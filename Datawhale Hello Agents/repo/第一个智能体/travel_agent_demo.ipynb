{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f67bd0",
   "metadata": {},
   "source": [
    "# æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ - ReAct æ™ºèƒ½ä½“æ¼”ç¤º\n",
    "\n",
    "æœ¬ Notebook æ¼”ç¤ºå¦‚ä½•ä»é›¶æ„å»ºä¸€ä¸ªåŸºäº ReAct èŒƒå¼çš„æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€‚\n",
    "\n",
    "## åŠŸèƒ½ç‰¹æ€§\n",
    "- ğŸŒ¤ï¸ æŸ¥è¯¢å®æ—¶å¤©æ°”\n",
    "- ğŸ›ï¸ æ¨èæ—…æ¸¸æ™¯ç‚¹\n",
    "- ğŸ¤– è‡ªä¸»è§„åˆ’ä»»åŠ¡æ‰§è¡Œæµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0e2ad",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf2bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "!pip install requests tavily-python openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6703c6b",
   "metadata": {},
   "source": [
    "## 2. å¯¼å…¥ä¾èµ–ä¸åŠ è½½ API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9fe986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tavily API Key å·²åŠ è½½\n",
      "âœ… LLM API Key å·²åŠ è½½\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from tavily import TavilyClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ .env æ–‡ä»¶\n",
    "load_dotenv\n",
    "\n",
    "# éªŒè¯ API Key æ˜¯å¦åŠ è½½æˆåŠŸ\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "print(f\"âœ… Tavily API Key å·²åŠ è½½\" if tavily_key else \"âŒ Tavily API Key æœªæ‰¾åˆ°\")\n",
    "\n",
    "# ä½¿ç”¨æ™ºè°±AI (å¯ä»¥æ ¹æ®éœ€è¦æ›´æ”¹ä¸ºå…¶ä»– LLM)\n",
    "API_KEY = os.getenv('ZHIPU_API_KEY')\n",
    "BASE_URL = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "MODEL_ID = \"glm-4-flash\"\n",
    "\n",
    "print(f\"âœ… LLM API Key å·²åŠ è½½\" if API_KEY else \"âŒ LLM API Key æœªæ‰¾åˆ°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f680ab",
   "metadata": {},
   "source": [
    "## 3. å®ç°å·¥å…·å‡½æ•°\n",
    "\n",
    "### 3.1 å¤©æ°”æŸ¥è¯¢å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb93573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ æµ‹è¯•å¤©æ°”æŸ¥è¯¢å·¥å…·:\n",
      "åŒ—äº¬å½“å‰å¤©æ°”:Clearï¼Œæ°”æ¸©-1æ‘„æ°åº¦\n"
     ]
    }
   ],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    é€šè¿‡è°ƒç”¨ wttr.in API æŸ¥è¯¢çœŸå®çš„å¤©æ°”ä¿¡æ¯ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "        city: åŸå¸‚åç§°\n",
    "    \n",
    "    è¿”å›:\n",
    "        å¤©æ°”ä¿¡æ¯çš„å­—ç¬¦ä¸²æè¿°\n",
    "    \"\"\"\n",
    "    # APIç«¯ç‚¹ï¼Œæˆ‘ä»¬è¯·æ±‚JSONæ ¼å¼çš„æ•°æ®\n",
    "    url = f\"https://wttr.in/{city}?format=j1\"\n",
    "    \n",
    "    try:\n",
    "        # å‘èµ·ç½‘ç»œè¯·æ±‚\n",
    "        response = requests.get(url)\n",
    "        # æ£€æŸ¥å“åº”çŠ¶æ€ç æ˜¯å¦ä¸º200 (æˆåŠŸ)\n",
    "        response.raise_for_status() \n",
    "        # è§£æè¿”å›çš„JSONæ•°æ®\n",
    "        data = response.json()\n",
    "        \n",
    "        # æå–å½“å‰å¤©æ°”çŠ¶å†µ\n",
    "        current_condition = data['current_condition'][0]\n",
    "        weather_desc = current_condition['weatherDesc'][0]['value']\n",
    "        temp_c = current_condition['temp_C']\n",
    "        \n",
    "        # æ ¼å¼åŒ–æˆè‡ªç„¶è¯­è¨€è¿”å›\n",
    "        return f\"{city}å½“å‰å¤©æ°”:{weather_desc}ï¼Œæ°”æ¸©{temp_c}æ‘„æ°åº¦\"\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # å¤„ç†ç½‘ç»œé”™è¯¯\n",
    "        return f\"é”™è¯¯:æŸ¥è¯¢å¤©æ°”æ—¶é‡åˆ°ç½‘ç»œé—®é¢˜ - {e}\"\n",
    "    except (KeyError, IndexError) as e:\n",
    "        # å¤„ç†æ•°æ®è§£æé”™è¯¯\n",
    "        return f\"é”™è¯¯:è§£æå¤©æ°”æ•°æ®å¤±è´¥ï¼Œå¯èƒ½æ˜¯åŸå¸‚åç§°æ— æ•ˆ - {e}\"\n",
    "\n",
    "# æµ‹è¯•å¤©æ°”æŸ¥è¯¢åŠŸèƒ½\n",
    "print(\"ğŸ”§ æµ‹è¯•å¤©æ°”æŸ¥è¯¢å·¥å…·:\")\n",
    "print(get_weather(\"åŒ—äº¬\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24868aa",
   "metadata": {},
   "source": [
    "### 3.2 æ™¯ç‚¹æ¨èå·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085e2734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ æµ‹è¯•æ™¯ç‚¹æ¨èå·¥å…·:\n",
      "Under sunny weather, visit the Summer Palace and the Great Wall for beautiful views and historical significance. Both are popular and well-known attractions in Beijing.\n"
     ]
    }
   ],
   "source": [
    "def get_attraction(city: str, weather: str) -> str:\n",
    "    \"\"\"\n",
    "    æ ¹æ®åŸå¸‚å’Œå¤©æ°”ï¼Œä½¿ç”¨Tavily Search APIæœç´¢å¹¶è¿”å›ä¼˜åŒ–åçš„æ™¯ç‚¹æ¨èã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "        city: åŸå¸‚åç§°\n",
    "        weather: å¤©æ°”æè¿°\n",
    "    \n",
    "    è¿”å›:\n",
    "        æ™¯ç‚¹æ¨èçš„å­—ç¬¦ä¸²æè¿°\n",
    "    \"\"\"\n",
    "    # 1. ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–APIå¯†é’¥\n",
    "    api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "    if not api_key:\n",
    "        return \"é”™è¯¯:æœªé…ç½®TAVILY_API_KEYç¯å¢ƒå˜é‡ã€‚\"\n",
    "\n",
    "    # 2. åˆå§‹åŒ–Tavilyå®¢æˆ·ç«¯\n",
    "    tavily = TavilyClient(api_key=api_key)\n",
    "    \n",
    "    # 3. æ„é€ ä¸€ä¸ªç²¾ç¡®çš„æŸ¥è¯¢\n",
    "    query = f\"'{city}' åœ¨'{weather}'å¤©æ°”ä¸‹æœ€å€¼å¾—å»çš„æ—…æ¸¸æ™¯ç‚¹æ¨èåŠç†ç”±\"\n",
    "    \n",
    "    try:\n",
    "        # 4. è°ƒç”¨APIï¼Œinclude_answer=Trueä¼šè¿”å›ä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”\n",
    "        response = tavily.search(query=query, search_depth=\"basic\", include_answer=True)\n",
    "        \n",
    "        # 5. Tavilyè¿”å›çš„ç»“æœå·²ç»éå¸¸å¹²å‡€ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨\n",
    "        # response['answer'] æ˜¯ä¸€ä¸ªåŸºäºæ‰€æœ‰æœç´¢ç»“æœçš„æ€»ç»“æ€§å›ç­”\n",
    "        if response.get(\"answer\"):\n",
    "            return response[\"answer\"]\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰ç»¼åˆæ€§å›ç­”ï¼Œåˆ™æ ¼å¼åŒ–åŸå§‹ç»“æœ\n",
    "        formatted_results = []\n",
    "        for result in response.get(\"results\", []):\n",
    "            formatted_results.append(f\"- {result['title']}: {result['content']}\")\n",
    "        \n",
    "        if not formatted_results:\n",
    "             return \"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ—…æ¸¸æ™¯ç‚¹æ¨èã€‚\"\n",
    "\n",
    "        return \"æ ¹æ®æœç´¢ï¼Œä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ä¿¡æ¯:\\n\" + \"\\n\".join(formatted_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"é”™è¯¯:æ‰§è¡ŒTavilyæœç´¢æ—¶å‡ºç°é—®é¢˜ - {e}\"\n",
    "\n",
    "# æµ‹è¯•æ™¯ç‚¹æ¨èåŠŸèƒ½\n",
    "print(\"ğŸ”§ æµ‹è¯•æ™¯ç‚¹æ¨èå·¥å…·:\")\n",
    "print(get_attraction(\"åŒ—äº¬\", \"Sunny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc90ae8",
   "metadata": {},
   "source": [
    "## 4. å®ç° LLM å®¢æˆ·ç«¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df9063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "class OpenAICompatibleClient:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„LLMæœåŠ¡çš„å®¢æˆ·ç«¯ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, model: str, api_key: str, base_url: str):\n",
    "        self.model = model\n",
    "        self.client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    def generate(self, prompt: str, system_prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM APIæ¥ç”Ÿæˆå›åº”ã€‚\"\"\"\n",
    "        print(\"ğŸ¤– æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\")\n",
    "        try:\n",
    "            messages = [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ]\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                stream=False\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            print(\"âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\")\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            return \"é”™è¯¯:è°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚\"\n",
    "\n",
    "# åˆå§‹åŒ– LLM å®¢æˆ·ç«¯\n",
    "llm = OpenAICompatibleClient(\n",
    "    model=MODEL_ID,\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabde974",
   "metadata": {},
   "source": [
    "## 5. å®šä¹‰æ™ºèƒ½ä½“ç³»ç»Ÿæç¤ºè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f99a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç³»ç»Ÿæç¤ºè¯å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå¹¶ä½¿ç”¨å¯ç”¨å·¥å…·ä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚\n",
    "\n",
    "# å¯ç”¨å·¥å…·:\n",
    "- `get_weather(city: str)`: æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ã€‚\n",
    "- `get_attraction(city: str, weather: str)`: æ ¹æ®åŸå¸‚å’Œå¤©æ°”æœç´¢æ¨èçš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
    "\n",
    "# è¡ŒåŠ¨æ ¼å¼:\n",
    "ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚é¦–å…ˆæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åæ˜¯ä½ è¦æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨ï¼Œæ¯æ¬¡å›å¤åªè¾“å‡ºä¸€å¯¹Thought-Actionï¼š\n",
    "Thought: [è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œä¸‹ä¸€æ­¥è®¡åˆ’]\n",
    "Action: [è¿™é‡Œæ˜¯ä½ è¦è°ƒç”¨çš„å·¥å…·ï¼Œæ ¼å¼ä¸º function_name(arg_name=\"arg_value\")]\n",
    "\n",
    "# ä»»åŠ¡å®Œæˆ:\n",
    "å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨`Action:`å­—æ®µåä½¿ç”¨ `finish(answer=\"...\")` æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "è¯·å¼€å§‹å§ï¼\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… ç³»ç»Ÿæç¤ºè¯å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215f914",
   "metadata": {},
   "source": [
    "## 6. å®ç°æ™ºèƒ½ä½“ä¸»å¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09f65b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ™ºèƒ½ä½“ä¸»å¾ªç¯å‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "def run_agent(user_prompt: str, max_iterations: int = 5):\n",
    "    \"\"\"\n",
    "    è¿è¡Œæ™ºèƒ½ä½“ä¸»å¾ªç¯ï¼Œå¤„ç†ç”¨æˆ·è¯·æ±‚ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "        user_prompt: ç”¨æˆ·è¾“å…¥çš„è¯·æ±‚\n",
    "        max_iterations: æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯\n",
    "    \"\"\"\n",
    "    # é…ç½®å·¥å…·å­—å…¸\n",
    "    available_tools = {\n",
    "        \"get_weather\": get_weather,\n",
    "        \"get_attraction\": get_attraction,\n",
    "    }\n",
    "    \n",
    "    # åˆå§‹åŒ–å¯¹è¯å†å²\n",
    "    prompt_history = [f\"ç”¨æˆ·è¯·æ±‚: {user_prompt}\"]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ‘¤ ç”¨æˆ·è¾“å…¥: {user_prompt}\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # è¿è¡Œä¸»å¾ªç¯\n",
    "    for i in range(max_iterations):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ”„ å¾ªç¯ {i+1}/{max_iterations}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. æ„å»ºå®Œæ•´çš„ Prompt\n",
    "        full_prompt = \"\\n\".join(prompt_history)\n",
    "        \n",
    "        # 2. è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒ\n",
    "        llm_output = llm.generate(full_prompt, system_prompt=AGENT_SYSTEM_PROMPT)\n",
    "        \n",
    "        # æ¨¡å‹å¯èƒ½ä¼šè¾“å‡ºå¤šä½™çš„Thought-Actionï¼Œéœ€è¦æˆªæ–­\n",
    "        match = re.search(r'(Thought:.*?Action:.*?)(?=\\n\\s*(?:Thought:|Action:|Observation:)|\\Z)', llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            truncated = match.group(1).strip()\n",
    "            if truncated != llm_output.strip():\n",
    "                llm_output = truncated\n",
    "                print(\"âš ï¸  å·²æˆªæ–­å¤šä½™çš„ Thought-Action å¯¹\")\n",
    "        \n",
    "        print(f\"\\nğŸ’­ æ¨¡å‹è¾“å‡º:\\n{llm_output}\\n\")\n",
    "        prompt_history.append(llm_output)\n",
    "        \n",
    "        # 3. è§£æå¹¶æ‰§è¡Œè¡ŒåŠ¨\n",
    "        action_match = re.search(r\"Action:(.*)\", llm_output, re.DOTALL)\n",
    "        if not action_match:\n",
    "            print(\"âŒ è§£æé”™è¯¯:æ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚\")\n",
    "            break\n",
    "        \n",
    "        action_str = action_match.group(1).strip()\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡\n",
    "        if action_str.startswith(\"finish\"):\n",
    "            final_match = re.search(r'finish\\(answer=\"(.*)\"\\)', action_str)\n",
    "            if final_match:\n",
    "                final_answer = final_match.group(1)\n",
    "                print(\"=\"*60)\n",
    "                print(\"ğŸ‰ ä»»åŠ¡å®Œæˆï¼\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\nğŸ“ æœ€ç»ˆç­”æ¡ˆ:\\n{final_answer}\\n\")\n",
    "                print(\"=\"*60)\n",
    "                return final_answer\n",
    "            else:\n",
    "                print(\"âŒ è§£æé”™è¯¯: finish å‡½æ•°æ ¼å¼ä¸æ­£ç¡®\")\n",
    "                break\n",
    "        \n",
    "        # æ‰§è¡Œå·¥å…·è°ƒç”¨\n",
    "        try:\n",
    "            tool_name = re.search(r\"(\\w+)\\(\", action_str).group(1)\n",
    "            args_str = re.search(r\"\\((.*)\\)\", action_str).group(1)\n",
    "            kwargs = dict(re.findall(r'(\\w+)=\"([^\"]*)\"', args_str))\n",
    "            \n",
    "            if tool_name in available_tools:\n",
    "                print(f\"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}({', '.join([f'{k}=\"{v}\"' for k, v in kwargs.items()])})\")\n",
    "                observation = available_tools[tool_name](**kwargs)\n",
    "            else:\n",
    "                observation = f\"é”™è¯¯:æœªå®šä¹‰çš„å·¥å…· '{tool_name}'\"\n",
    "        except Exception as e:\n",
    "            observation = f\"é”™è¯¯:è§£ææˆ–æ‰§è¡Œå·¥å…·æ—¶å‡ºé”™ - {e}\"\n",
    "        \n",
    "        # 4. è®°å½•è§‚å¯Ÿç»“æœ\n",
    "        observation_str = f\"Observation: {observation}\"\n",
    "        print(f\"\\nğŸ‘ï¸  {observation_str}\\n\")\n",
    "        prompt_history.append(observation_str)\n",
    "    \n",
    "    print(\"\\nâš ï¸  è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œä»»åŠ¡æœªå®Œæˆã€‚\")\n",
    "    return None\n",
    "\n",
    "print(\"âœ… æ™ºèƒ½ä½“ä¸»å¾ªç¯å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c0441",
   "metadata": {},
   "source": [
    "## 7. è¿è¡Œæ™ºèƒ½ä½“æ¼”ç¤º\n",
    "\n",
    "### ç¤ºä¾‹ 1: æŸ¥è¯¢å¤©æ°”å¹¶æ¨èæ™¯ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2646a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ‘¤ ç”¨æˆ·è¾“å…¥: ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ”„ å¾ªç¯ 1/5\n",
      "============================================================\n",
      "ğŸ¤– æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "\n",
      "ğŸ’­ æ¨¡å‹è¾“å‡º:\n",
      "Thought: é¦–å…ˆéœ€è¦æŸ¥è¯¢åŒ—äº¬çš„å®æ—¶å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æƒ…å†µæ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "Action: get_weather(city=\"åŒ—äº¬\")\n",
      "\n",
      "ğŸ”§ æ‰§è¡Œå·¥å…·: get_weather(city=\"åŒ—äº¬\")\n",
      "\n",
      "ğŸ‘ï¸  Observation: åŒ—äº¬å½“å‰å¤©æ°”:Clearï¼Œæ°”æ¸©-1æ‘„æ°åº¦\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ”„ å¾ªç¯ 2/5\n",
      "============================================================\n",
      "ğŸ¤– æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "\n",
      "ğŸ’­ æ¨¡å‹è¾“å‡º:\n",
      "Thought: åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæˆ‘å¯ä»¥æ¨èä¸€äº›é€‚åˆæ™´å¤©çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "Action: get_attraction(city=\"åŒ—äº¬\", weather=\"Clear\")\n",
      "\n",
      "ğŸ”§ æ‰§è¡Œå·¥å…·: get_attraction(city=\"åŒ—äº¬\", weather=\"Clear\")\n",
      "\n",
      "ğŸ‘ï¸  Observation: In clear weather, the Forbidden City and Tiananmen Square are top Beijing attractions. The Great Wall at Mutianyu is also highly recommended. These sites offer historical insights and scenic views.\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ”„ å¾ªç¯ 3/5\n",
      "============================================================\n",
      "ğŸ¤– æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "\n",
      "ğŸ’­ æ¨¡å‹è¾“å‡º:\n",
      "Thought: æˆ‘å·²ç»æŸ¥è¯¢åˆ°äº†åŒ—äº¬çš„å¤©æ°”ï¼Œå¹¶ä¸”çŸ¥é“ä»Šå¤©æ˜¯æ™´å¤©ã€‚ç°åœ¨æˆ‘å°†æ ¹æ®è¿™ä¸ªå¤©æ°”æƒ…å†µæ¨èä¸€äº›æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "Action: finish(answer=\"åœ¨åŒ—äº¬æ™´å¤©çš„æƒ…å†µä¸‹ï¼Œæˆ‘æ¨èæ‚¨å»æ•…å®«ã€å¤©å®‰é—¨å¹¿åœºæˆ–è€…æ…•ç”°å³ªé•¿åŸã€‚è¿™äº›åœ°æ–¹ä¸ä»…èƒ½å¤Ÿè®©æ‚¨äº†è§£å†å²ï¼Œè¿˜èƒ½æ¬£èµåˆ°ç¾ä¸½çš„é£æ™¯ã€‚\")\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ä»»åŠ¡å®Œæˆï¼\n",
      "============================================================\n",
      "\n",
      "ğŸ“ æœ€ç»ˆç­”æ¡ˆ:\n",
      "åœ¨åŒ—äº¬æ™´å¤©çš„æƒ…å†µä¸‹ï¼Œæˆ‘æ¨èæ‚¨å»æ•…å®«ã€å¤©å®‰é—¨å¹¿åœºæˆ–è€…æ…•ç”°å³ªé•¿åŸã€‚è¿™äº›åœ°æ–¹ä¸ä»…èƒ½å¤Ÿè®©æ‚¨äº†è§£å†å²ï¼Œè¿˜èƒ½æ¬£èµåˆ°ç¾ä¸½çš„é£æ™¯ã€‚\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'åœ¨åŒ—äº¬æ™´å¤©çš„æƒ…å†µä¸‹ï¼Œæˆ‘æ¨èæ‚¨å»æ•…å®«ã€å¤©å®‰é—¨å¹¿åœºæˆ–è€…æ…•ç”°å³ªé•¿åŸã€‚è¿™äº›åœ°æ–¹ä¸ä»…èƒ½å¤Ÿè®©æ‚¨äº†è§£å†å²ï¼Œè¿˜èƒ½æ¬£èµåˆ°ç¾ä¸½çš„é£æ™¯ã€‚'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç¤ºä¾‹ 1: åŒ—äº¬æ—…æ¸¸\n",
    "user_request_1 = \"ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\"\n",
    "run_agent(user_request_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787fa55",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 2: ä¸Šæµ·æ—…æ¸¸è§„åˆ’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹ 2: ä¸Šæµ·æ—…æ¸¸\n",
    "user_request_2 = \"æˆ‘æƒ³å»ä¸Šæµ·æ—…æ¸¸ï¼Œå¸®æˆ‘æŸ¥ä¸€ä¸‹ä¸Šæµ·çš„å¤©æ°”ï¼Œå¹¶æ¨èé€‚åˆçš„æ™¯ç‚¹ã€‚\"\n",
    "run_agent(user_request_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6b992",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 3: è‡ªå®šä¹‰æŸ¥è¯¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹ 3: è‡ªå®šä¹‰æŸ¥è¯¢ - ä½ å¯ä»¥ä¿®æ”¹è¿™é‡Œçš„å†…å®¹\n",
    "custom_request = \"å¸®æˆ‘æŸ¥è¯¢æ­å·çš„å¤©æ°”ï¼Œå¦‚æœå¤©æ°”å¥½çš„è¯æ¨èä¸€äº›æˆ·å¤–æ™¯ç‚¹ã€‚\"\n",
    "run_agent(custom_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9379918e",
   "metadata": {},
   "source": [
    "## 8. æ€»ç»“\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "1. **ReAct èŒƒå¼**: Thoughtï¼ˆæ€è€ƒï¼‰â†’ Actionï¼ˆè¡ŒåŠ¨ï¼‰â†’ Observationï¼ˆè§‚å¯Ÿï¼‰\n",
    "2. **å·¥å…·è°ƒç”¨**: æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªä¸»å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå·¥å…·\n",
    "3. **å¾ªç¯æ‰§è¡Œ**: é€šè¿‡å¤šè½®äº¤äº’é€æ­¥å®Œæˆå¤æ‚ä»»åŠ¡\n",
    "\n",
    "### ğŸ”§ æŠ€æœ¯è¦ç‚¹\n",
    "\n",
    "- ä½¿ç”¨ `wttr.in` API è·å–å®æ—¶å¤©æ°”æ•°æ®\n",
    "- ä½¿ç”¨ `Tavily` è¿›è¡Œæ™ºèƒ½æœç´¢å’Œæ™¯ç‚¹æ¨è\n",
    "- ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹\n",
    "- æ­£åˆ™è¡¨è¾¾å¼è§£æ LLM è¾“å‡ºçš„ç»“æ„åŒ–ä¿¡æ¯\n",
    "\n",
    "### ğŸš€ æ‰©å±•æ–¹å‘\n",
    "\n",
    "1. æ·»åŠ æ›´å¤šå·¥å…·ï¼ˆé…’åº—é¢„è®¢ã€äº¤é€šæŸ¥è¯¢ç­‰ï¼‰\n",
    "2. ä¼˜åŒ–æç¤ºè¯å·¥ç¨‹ï¼Œæé«˜ä»»åŠ¡å®Œæˆç‡\n",
    "3. æ·»åŠ è®°å¿†æœºåˆ¶ï¼Œæ”¯æŒå¤šè½®å¯¹è¯\n",
    "4. å®ç°é”™è¯¯é‡è¯•å’Œå¼‚å¸¸å¤„ç†æœºåˆ¶"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
